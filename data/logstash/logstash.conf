input{
     jdbc {
         # jdbc_driver_library=>"/usr/share/logstash/odbc_tools/mysql-connector-java-8.0.12.jar"
         # 驱动类名
         jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
         # mysql 数据库链接,blog为数据库名，根据自己实际情况修改
         jdbc_connection_string => "jdbc:mysql://192.168.2.16:3306/log_stash?useJDBCCompliantTimezoneShift=true&useSSL=false&useLegacyDatetimeCode=false&serverTimezone=Asia/Shanghai"
         # 连接数据库用户名
         jdbc_user => "root"
         # 连接数据库密码
         jdbc_password => "root"
         # 是否启用分页
         jdbc_paging_enabled => "true"
         jdbc_page_size => "50000" 
         # 设置监听间隔  各字段含义（由左至右） 分、时、天、月、年，全部为*默认含义为每分钟都更新
         # 每天凌晨1:00自动执行   "0 1 * * *"
         schedule => "* * * * *"
         # 定义执行sql文路径及名称
         # statement_filepath => "/home/logstash/blog.sql"
         # 直接写sql语句用这个，t_user为需要把数据导向elasticsearch
         statement => "select * from t_data"
         type => "jdbc"
       }
	tcp {
	    mode => "server"
	    host => "0.0.0.0"
	    port => 4560
	    codec => json_lines
	    type => "tcp"
	  }
       
}

filter{
    json{
        source => "message"
        remove_field => ["message"]
    }
}
#output插件配置
output{
    if [type]=="jdbc" {
      elasticsearch {
        #ES索引名称（自己定义的）
        index => "log_stash_t_data"
        #自增ID编号
        document_id => "%{itemid}"
    		# hosts => ["es:9200","es-d1:9200","es-d2:9200"]
		    hosts => ["es:9200"]
      }
   }
   if[type]=="tcp"{
	    elasticsearch {
	    hosts => "es:9200"
	    index => "febs-logstash-%{+YYYY.MM.dd}"
	      }
     }
 }
